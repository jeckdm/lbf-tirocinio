\documentclass[4apaper,11pt]{article}
\usepackage[italian]{babel}
\usepackage{parskip}

% Bibliografia
\usepackage[backend = biber, citestyle = numeric]{biblatex}
\addbibresource{bibliografia/bibliografia.bib}

\begin{document}
Presentati per la prima volta in \cite{Bloom1970SpacetimeTI}, i filtri di Bloom vengono oggi utilizzati in molteplici contesti: database \cite{kraska2018case}, web caching \cite{Maggs15algorithmicnuggets}, controllo di indirizzi \cite{Dharmapurikar2006LongestPM}, e molti altri. In breve, un filtro di Bloom è una struttura dati probabilistica ed efficiente in termini di spazio, utilizzata per verificare l'appartenenza di un elemento a un insieme; un filtro di Bloom può generare falsi positivi, ma non falsi negativi.

Nel corso degli anni sono state proposte diverse varianti del filtro di Bloom, che cercano di migliorare l'efficienza della struttura originale. Questo elaborato, che descrive il mio lavoro di tirocinio, si concentra su due varianti del filtro classico: il filtro di Bloom appreso, o learned Bloom filter (LBF) \cite{kraska2018case}, e il sandwiched learned Bloom filter (SLBF) \cite{10.5555/3326943.3326986}. Entrambe si caratterizzano per l'utilizzo di un classificatore al fine di ridurre lo spazio occupato dalla struttura. Più nel dettaglio, l'LBF affianca al classificatore un filtro di Bloom, detto di backup, utile a eliminare i falsi negativi prodotti dal classificatore; l'SLBF, invece, aggiunge un ulteriore filtro di Bloom iniziale, utile a diminuire il lavoro del classificatore e, di conseguenza, del filtro di backup, formando nel complesso una struttura più efficiente e robusta rispetto alle query presentate.

Il problema che viene preso in considerazione è di classificazione di URL: l'obiettivo è discernere, nel modo più accurato possibile, tra URL legittimi e URL di phishing, ovvero URL legati a pagine web costruite al fine di indurre l'utente a rivelare dati sensibili. Gli esperimenti effettuati partono dal classificatore presentato in \cite{ma2020}\footnote{Al momento dell'inizio del tirocinio, l'articolo citato e il relativo codice erano disponibili in rete. Attualmente non sono più reperibili.}, ovvero una rete ricorrente, e ne forniscono un'analisi dal punto di vista delle performance, e dei filtri costruiti. Il classificatore e i relativi filtri vengono poi messi a confronto con un modello più semplice: il fine è quello di verificare se l'utilizzo di modelli meno complessi, e di conseguenza meno onerosi in termini di spazio, possa portare a filtri appresi più efficienti.

Riassumendo, questo elaborato si propone principalmente di: 
\begin{itemize}
    \item presentare un confronto tra reti neurali ricorrenti, basate su Gated Recurrent Unit, e reti feedforward, basate su un percettrone multistrato,
    \item presentare i risultati di analisi empiriche effettuate sui filtri appresi costruiti con i classificatori descritti,
    \item presentare un confronto tra lo spazio occupato dai filtri ottenuti con i diversi classificatori, e un confronto tra le taglie delle due tipologie di filtri appresi.
\end{itemize}
Inoltre, seppur l'elaborato si concentri prevalentemente sulle prestazioni in termini di spazio occupato, in alcune applicazioni anche il tempo di accesso rappresenta un aspetto altrettanto importante. Per questo motivo, seppur brevemente, vengono analizzati i tempi di accesso di un filtro classico, confrontandoli con quelli delle due varianti apprese. 

I risultati presentati hanno evidenziato, per il problema considerato, delle prestazioni migliori da parte del percettrone nel problema di classificazione di URL. Conseguentemente, anche le taglie dei filtri appresi ottenuti utilizzando tale modello sono risultate più basse rispetto a quelle ottenute sfruttando la rete ricorrente. Infine, un confronto tra le taglie delle due tipologie di filtro di Bloom appreso ha confermato, come già mostrato in altri lavori, una maggiore efficienza del sandwiched learned Bloom filter a parità di tasso di falsi positivi.

Tuttavia, è anche emerso che le varianti apprese del filtro risultano più lente di 1-2 ordini di grandezza rispetto al filtro classico, ciò potrebbe risultare più o meno limitante a seconda dell'ambito in cui la struttura viene utilizzata: in contesti dove lo spazio è una risorsa preziosa, questo compromesso risulta comunque accettabile. 

Futuri lavori potrebbero quindi concentrarsi su diversi aspetti, primo fra questi l'analisi di filtri appresi con tipologie di classificatore più semplici e non basate su reti neurali, come i classificatori lineari, al fine di cercare un miglior compromesso tra spazio risparmiato e tempi d'accesso. Un altro aspetto su cui concentrarsi potrebbe essere la ricerca di criteri ottimali, attualmente assenti, per la scelta della soglia $\tau$. In generale, le potenzialità di queste strutture dati vanno ancora comprese pienamente.

Infine, l'elaborato è strutturato come segue: i Capitoli 1, 2 e 3 forniscono un'introduzione teorica agli aspetti legati agli esperimenti: rispettivamente descrivono filtri di Bloom, apprendimento automatico (con particolare attenzione a percettroni multistrato e reti ricorrenti) e filtri di Bloom appresi. I Capitoli 4 e 5, invece, descrivono la configurazione, l'implementazione e i risultati degli esperimenti. 
\printbibliography
\end{document}