\documentclass[../../main.tex]{subfiles}

\graphicspath{{\subfix{../../immagini/}}}

\begin{document}    
    Presentati per la prima volta in \cite{Bloom1970SpacetimeTI}, i filtri di Bloom vengono oggi utilizzati in molteplici contesti: database \cite{kraska2018case}, web caching \cite{Maggs15algorithmicnuggets}, controllo di indirizzi \cite{Dharmapurikar2006LongestPM}, e molti altri. In breve, un filtro di Bloom è una struttura dati probabilistica ed efficiente in termini di spazio, utilizzata per verificare l'appartenenza di un elemento a un insieme; un filtro di Bloom può generare falsi positivi, ma non falsi negativi.

    Nel corso degli anni sono state proposte diverse varianti del filtro di Bloom, che cercano di migliorare l'efficienza della struttura originale. Questo elaborato, che descrive il mio lavoro di tirocinio, si concentra su due varianti del filtro classico: il filtro di Bloom appreso, o learned Bloom filter (LBF) \cite{kraska2018case}, e il sandwiched learned Bloom filter (SLBF) \cite{10.5555/3326943.3326986}. Entrambe si caratterizzano per l'utilizzo di un classificatore al fine di ridurre lo spazio occupato dalla struttura. Più nel dettaglio, l'LBF affianca al classificatore un filtro di Bloom, detto di backup, utile a eliminare i falsi negativi prodotti dal classificatore; l'SLBF, invece, aggiunge un ulteriore filtro di Bloom iniziale, utile a diminuire il lavoro del classificatore e, di conseguenza, del filtro di backup, formando nel complesso una struttura più efficiente e robusta rispetto alle query presentate.

    Il problema che viene preso in considerazione è di classificazione di URL: l'obiettivo è discernere, nel modo più accurato possibile, tra URL legittimi e URL di phishing, ovvero URL legati a pagine web costruite al fine di indurre l'utente a rivelare dati sensibili. Gli esperimenti effettuati partono dal classificatore presentato in \cite{ma2020}\footnote{Al momento dell'inizio del tirocinio, l'articolo citato e il relativo codice erano disponibili in rete. Attualmente non sono più reperibili.}, ossia una rete ricorrente, e ne forniscono un'analisi dal punto di vista delle performance, e dei filtri costruiti. Il classificatore e i relativi filtri vengono poi messi a confronto con un modello più semplice: il fine è quello di verificare se l'utilizzo di modelli meno complessi, e di conseguenza meno onerosi in termini di spazio, possa portare a filtri appresi più efficienti. Come verrà evidenziato dai risultati, il classificatore più semplice (un percettrone multistrato) rappresenta, nel contesto presentato, la scelta migliore.

    Riassumendo, questo elaborato si propone principalmente di: 
    \begin{itemize}
        \item presentare un confronto tra le performance dei classificatori illustrati in \cite{ma2020} e quelle di un modello più semplice, basato su un percettrone multistrato,
        \item presentare i risultati di analisi empiriche effettuate sui filtri appresi costruiti con i classificatori descritti,
        \item presentare un confronto tra lo spazio occupato dai filtri ottenuti con i diversi classificatori, e un confronto tra le taglie delle due tipologie di filtri appresi.
    \end{itemize}
    In ultimo, seppur brevemente, vengono trattati i tempi di accesso di un filtro classico, confrontandoli con le due varianti apprese. Come prevedibile, il filtro di Bloom classico, essendo in generale una struttura meno complessa rispetto alle controparti apprese, si rivela più efficiente sotto questo punto di vista. 

    L'elaborato è strutturato come segue: i Capitoli \ref{chap:FiltriBloom}, \ref{chap:ApprendimentoAutomatico} e \ref{chap:filtriAppresi} forniscono un'introduzione teorica agli aspetti legati agli esperimenti: rispettivamente descrivono filtri di Bloom, apprendimento automatico (con particolare attenzione a percettroni multistrato e reti ricorrenti) e filtri di Bloom appresi. I Capitoli \ref{chap:Esperimenti} e \ref{chap:Risultati}, invece, presentano strumenti, implementazione e risultati degli esperimenti. 
\end{document}